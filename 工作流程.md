# 📊 工作流程說明

本專案旨在建構一個可解釋且具備泛化能力的交通事故類型分類模型，藉由資料清洗、特徵工程與模型優化，最終達到準確預測並理解車禍發生之主要影響因素。以下為詳細工作流程。

---

## 📁 Step 1：資料整併與預處理

### 💡 問題
1. 各年度 Excel 檔案工作表結構不一致，造成讀取效率低。
2. 資料中存在大量空缺值，且欄位命名不統一。

### ✅ 解決策略
- **統一欄位命名與格式**：選取具有意義且可用率高的欄位，進行標準化命名。
- **合併多年度資料**：將 105～109 年各年度資料合併為單一 `CSV` 檔案，作為後續分析的輸入。
- **新增時間與區域特徵**：轉換時間欄位為 `year`、`month`、`hour` 等，並將區域轉為數值編碼。
- **空缺值初步處理**：保留完整資料作為初步建模依據；高缺漏欄位將視情況捨棄或留待補值。

### 📌 保留特徵類型
- **時間特徵**：年、月、日、時、季度、晝夜別等。
- **地理特徵**：行政區、經緯度。
- **當事人特徵**：性別、年齡、國籍。
- **現場環境**：天候、光線、速限、道路型態與位置等。
- **事故特徵**：死亡人數、受傷人數、車損、事故類型與主因等。

---

## 📁 Step 2：特徵工程與選擇

### 💡 問題
1. 部分欄位仍存在空缺值。
2. 非數值型資料需轉為模型可接受格式。
3. 特徵維度過高，需進行重要性篩選。

### ✅ 解決策略
- **選取完整資料子集**：先針對無空值樣本進行建模，確認資料品質與模型穩定性。
- **Random Forest 特徵重要性排序**：訓練隨機森林模型，分析並排序各特徵對事故分類之貢獻度。
- **One-Hot Encoding 編碼**：針對所有分類型特徵（如天候、光線、號誌等）進行 One-Hot 編碼處理。

---

## 📁 Step 3：模型訓練與評估

### ✅ 執行流程
1. **模型選擇**：考慮使用分類器如 `DecisionTree`, `RandomForest`, `GradientBoosting` 等。
2. **參數調整**：運用 `GridSearchCV` 或 `RandomizedSearchCV` 進行超參數搜尋。
3. **模型驗證**：採用 K-Fold Cross Validation 驗證模型效能並避免 overfitting。
4. **效能評估**：觀察指標包含準確率、Recall、F1-score 與 Confusion Matrix。

---

## 📁 Step 4：模型強化與可解釋性分析

### ✅ 執行策略
- **模型整合提升**：結合 Bagging、Boosting 方法進行整合學習，提升預測穩定度與準確性。
- **SHAP 解釋分析**：使用 SHAP (SHapley Additive exPlanations) 對最終模型進行特徵貢獻度解釋，視覺化顯示模型如何根據不同變數做出分類判斷。
- **年度比較與趨勢解釋**：分析不同年度 SHAP 分布變化，以找出影響事故結果的結構性趨勢差異。

---

## 📌 小結

透過以上四個模組化階段，專案實現了：
- 高品質的資料處理與合併
- 有效的特徵選擇與轉換
- 高準確性的模型訓練與調參
- 可視化的模型解釋與實務分析價值

此流程亦具備可擴充性與模組化設計，適用於其他領域的分類任務分析。
