# DL2025_Team5_Cause_detection_for_increase_in_traffic_accidents


## a. 概述：
主題: 交通事故增加原因偵測(Cause detection for increase in traffic accidents)
簡介：
本研究旨在深入剖析台北市警察局提供之105年至109年期間的道路交通事故調查報告，探討導致近年交通事故發生率上升的潛在原因。
透過資料分析與模型建構，我們將從多項指標中尋找影響交通事故發生的關鍵因素。
希望藉由本研究所得到的發現，能夠提供具體而可行的建議，協助政府單位在制定交通政策時，有更明確的依據，以提升整體道路安全與市民通行安全。

研究目標：
本研究以台北市警察局105年至109年之道路交通事故調查資料為基礎，透過統計分析與機器學習等方法，挖掘影響事故數量變化的潛在因子，
進一步解釋近年交通事故增加的主因，期望為交通管理與安全政策的優化提供實證支持。

# 此資料集為非公開資料!!!
## b. 專案資料：
來源：台北市警察局臺北市交通事故資料
資料處理過程 :

## 執行方法
專案根目錄
 -  │ 
 -  ├－105年A1-A4所有當事人.xlsx #資料資料
 -  ├－106年A1-A4所有當事人.xlsx #資料資料
 -  ├－107年A1-A4所有當事人(新增戶籍地).xlsx #資料資料
 -  ├－108年A1-A4所有當事人(新增戶籍地).xlsx #資料資料
 -  ├－109年A1-A4所有當事人(新增戶籍地).xlsx #資料資料
 -  ├── data.py # 執行步驟1：資料處理
 -  ├── RandomForest.py # 執行步驟2：特徵分析
 -  ├── model_training.py # 執行步驟3：模型訓練與評估
 -  ├── shap_analysis.py # 執行步驟4：結果分析
 -  ├── step1.csv # 步驟1產生的合併資料文件
 -  ├── step2.csv # 步驟2產生的特徵重要性文件
 -  └── model # 專案簡介與執行方法（本文件）
 -  └──各種模型
## 簡介

本計畫旨在透過資料處理、特徵分析和模型訓練，建構一個高效的車禍類型分類模型，並使用SHAP分析每年車禍結果的分類變化。以下是具體的執行步驟。

## 環境需求
 -  Python 3.8+
 -  pandas, numpy
 -  scikit-learn
 -  shap
 -  openpyxl

### 步驟1：資料處理

#### `python data.py`

##### 功能
- 讀取Excel文件，合併處理105年至109年的數據，並產生`step1.csv`文件。

##### 實現
- 使用`pandas`庫讀取Excel文件，處理資料空缺和資料排版不一致的問題。
- 合併多年的數據，統一格式，轉換為單一的csv檔。

### 步驟2：特徵分析

#### `python RandomForest.py`

##### 功能
- 讀取`step1.csv`文件，透過隨機森林分析特徵的重要性，並將貢獻較大的特徵輸出到`step2.csv`文件。

##### 實現
- 使用`pandas`庫讀取`step1.csv`文件，進行資料預處理。
- 使用`sklearn`庫的`RandomForestClassifier`分析特徵重要性，篩選出貢獻較大的特徵。

### 步驟3：模型訓練與評估

#### `資料合并以及特徵提取model1_input.py`
##### 功能
- 產生`step1.csv`文件。

#### `python model1_分類車禍類型.py`
##### 功能
- 讀取`step1.csv`文件，使用各種分類模型調試並選擇最佳模型進行車禍類型分類。

##### 實現
- 嘗試多種分類模型（如決策樹、隨機森林、梯度提升等），調整參數並選擇最佳模型。

### 步驟4：結果分析

#### `python shap_analysis.py`

##### 功能
- 使用調適好的最佳模型結合SHAP分析每年車禍結果的分類變化。

##### 實現
- 使用`pandas`函式庫讀取數據，結合SHAP函式庫分析特徵對預測結果的貢獻。
- 輸出每年車禍類型分類結果的變化趨勢。



## 詳細工作流程

1. **資料準備**
    - 規範化並合併資料為單一csv檔。
    - 處理空缺值：根據特徵的重要性和空缺值的比例，選擇適當的方法處理空缺值，如平均值填補、中位數填補或使用機器學習模型預測填補。

2. **特徵選擇與編碼**
    - 初步特徵選擇：選擇完整數據，使用RandomForestClassifier進行特徵重要性分析，篩選出關鍵特徵。
    - 對分類特徵進行one-hot編碼：將所有非數值型特徵轉換為適合模型訓練的格式。

3. **模型訓練與評估**
    - 模型選擇：選擇幾個常用的分類模型，如決策樹、隨機森林、梯度提升等。
    - 模型訓練：使用選定的模型進行訓練，調整參數以獲得最佳效能。
    - 模型評估：使用交叉驗證方法評估模型的效能，選擇最佳模型。

4. **模型提升與解釋**
    - 模型提升：透過超參數調優和整合方法（如整合學習、Bagging、Boosting等）來提高模型的準確性和穩健性。
    - 模型解釋：使用SHAP值分析模型的決策過程，解釋關鍵特徵對預測結果的影響，並識別出影響事故的主要因素。

### 步驟1：資料處理

#### 問題
1. 在Python中讀取和處理Excel資料速度緩慢：資料排版不一致，有些在第一頁，有些在第二頁。
2. 資料空缺：資料集中存在許多空缺值。

#### 解決方法
1. **統一化**
    - 將資料合併並轉換為單一的csv文件，方便後續拆分為訓練集、測試集和驗證集。

2. **特徵篩選（初步）**
    - 盡量保留足夠完整的特徵。
    - 對於空缺超過70%的特徵，如果沒有明顯的用途，可以先捨棄；如果有半監督學習或填補方法，可以在後續處理時再考慮使用這些數據。

#### 資料保留
1. **地理特徵**
    - 保留座標和區域名稱（轉換為程式碼）。

2. **時間特徵**
    - 晝夜、日、月、年、時間。

3. **人物特徵**
    - 年齡、性別、國籍。

4. **現場特徵**
    - 天氣、光線、道路類型、限速、道路形態、事故位置、事故類型及型態。

5. **案件特徵**
    - 處理別、案號、當事人序、車種。

6. **其他特徵**
    - 死亡人數、2-30日死亡人數、受傷人數、路面狀況1、路面狀況2、路面狀況3、道路障礙1、道路障礙2、號志1、號志2、車道劃分-分向、車道劃分-分道1、車道劃分-分道2、車道劃分-分道3、重大車損、受傷程度、主要傷處、行動電話、車輛用途、當事人行動狀態、駕駛資格情形、駕駛執照種類、飲酒情形、主要車損、其他車損、肇逃否、職業、旅次目的。

7. **結果**
    - 肇因碼-個別、肇因碼-主要。

**注意**：資料多以程式碼呈現，對照表見附圖（對照表.jpg）。

### 步驟2：特徵處理/選擇

#### 目前狀態
   - 已將所有資料轉為csv格式，並保留大部分可考慮使用的特徵。

#### 問題
1. 空缺值尚未處理。
2. 需要篩選出對結果有關鍵影響的特徵。
3. 需要確定是否對每個特徵進行後續分析/處理。

#### 解決方法
1. **選擇特定特徵下完全沒有空缺的資料（完整資料）**
    - 首先處理沒有空缺的子集資料。

2. **特徵重要性分析**
    - 使用RandomForestClassifier分析每個特徵對分類結果的貢獻。
    - 篩選出對結果有顯著貢獻的特徵用於後續模型訓練。

3. **編碼非數值型特徵**
    - 對所有非數值型特徵進行one-hot編碼，準備進行機器學習模型訓練。

### 步驟3：模型測試
#### 模型結構
    - 採用 RandomForestClassifier 為主要分類模型。
    - 比較 DecisionTree, XGBoost, GradientBoosting 模型表現。
#### 操作
1. **模型選擇**
    - 選擇合適的分類模型（如決策樹、隨機森林、梯度提升）。

2. **模型提升**
    - 使用超參數調優、交叉驗證和整合方法來提高事故預測準確率。

3. **解釋性**
    - 利用SHAP（Shapley Additive Explanations）分析並解釋導致事故上升的因素。

#### 工作流程詳解
1. **資料準備**
    - 將所有資料標準化，統一格式後合併為一個csv檔。
    - 處理空缺值：可以使用平均值填補、中位數填補或透過機器學習模型進行預測填補，具體選擇方法依據特徵的重要性和空缺值的比例決定。

2. **特徵選擇與編碼**
    - 進行初步特徵選擇：選擇那些沒有空缺值的數據，使用RandomForestClassifier分析每個特徵的重要性，從中篩選出關鍵特徵。
    - 對非數值型特徵進行one-hot編碼：將所有分類特徵轉換為適合模型訓練的格式，確保資料的一致性和模型的準確性。

3. **模型訓練與評估**
    - 模型選擇：選擇常用的分類模型，如決策樹、隨機森林和梯度提升，進行初步模型訓練。
    - 模型訓練：使用訓練資料集進行模型訓練，並調整參數以最佳化模型效能。
    - 模型評估：採用交叉驗證的方法評估模型效能，選擇表現最佳的模型進行進一步最佳化。

4. **模型提升與解釋**
    - 模型提升：透過超參數調優和整合方法（例如Bagging和Boosting）來提升模型的預測準確性和穩定性。
    - 模型解釋：使用SHAP值分析模型的決策過程，解釋每個特徵對預測結果的影響，並識別影響事故發生的主要因素，從而提升模型的可解釋性。


### 改進方向&改進方法

#### 資料處理

1. **加速Excel讀取**
    - 採用 pandas.read_excel 搭配 openpyxl 或 xlrd 優化載入效率，並可實作多工處理加速多檔讀取。
    - 若資料量龐大，可使用 dask 進行分散式資料讀取與處理，減輕記憶體負擔。
    - 自動偵測多工作表資料並合併成單一資料框，提升資料前處理效率。

2. **處理資料空缺**
    - 導入進階補值方法，如線性插值（interpolation）、KNN 預測補值，提升資料品質。
    - 利用相似樣本填補策略，結合距離計算選擇近似值進行填補。
    - 採用資料增強技術產生合理樣本，降低資料稀疏性對模型的干擾。

#### 特徵處理與選擇

1. **高級特徵選擇**
    - 應用 Boruta 演算法、LASSO 迴歸或基於樹模型的重要性排序，篩選具影響力的特徵。
    - 採用嵌入式方法結合模型訓練同時完成特徵選擇。
    - 運用 PCA 或 LDA 等降維技術，降低維度並保留資訊量。

2. **處理非數值特徵**
    - 對類別特徵進行目標編碼（Target Encoding），取代傳統 One-Hot，降低維度並避免稀疏化。
    - 採用嵌入向量（Embedding）技術處理高基數特徵，增強模型表達能力。

#### 模型訓練與評估

1. **選擇多樣化模型**
    - 除傳統分類模型外，引入 XGBoost、LightGBM 等集成學習演算法，以及神經網路等深度學習模型。
    - 採用 AutoML 工具（如 TPOT、AutoKeras）自動探索最佳模型架構與超參數組合，加速開發流程。
2. **模型評估與驗證**
    - 結合多項指標（如 F1-score、ROC-AUC、Precision-Recall）進行模型效能評估，避免單一指標偏誤。
    - 使用 k-fold 交叉驗證驗證模型穩定性與泛化能力。
    - 執行錯誤樣本分析，聚焦高風險誤判案例進行調整。

#### 模型提升與解釋

1. **提升模型性能**
    - 結合多模型（Stacking）整合預測結果，提升整體準確性與穩健性。
    - 採用對抗訓練（Adversarial Training）增強模型對異常樣本的適應能力。
    - 建立線上學習機制（Online Learning），讓模型能持續調整以反映資料變化。

2. **增強模型解釋性**
    - 搭配 SHAP、LIME 等模型解釋工具，從全局與局部層面說明預測邏輯。
    - 建構互動式視覺化介面，展示特徵重要性與模型決策過程。
    - 融合領域知識，邀請專家審閱與交叉驗證解釋結果，確保分析具實務價值與可信度。




#
